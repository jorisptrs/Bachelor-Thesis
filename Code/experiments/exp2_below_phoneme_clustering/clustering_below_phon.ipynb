{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b2514c",
   "metadata": {},
   "source": [
    "# Clustering: Below-Phoneme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f28326",
   "metadata": {},
   "source": [
    "Import libraries and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import lib.clustering.clustering_metrics\n",
    "\n",
    "directory = os.path.abspath('/Users/joris/Documents/Work/bsc ai/bt/Bachelor-Thesis/code')\n",
    "sys.path.append(directory)\n",
    "\n",
    "from dataset.loading import DataLoader\n",
    "from lib.plotting.plot_1 import *\n",
    "from lib.esn import ESN\n",
    "from lib.clustering.clustering_metrics import *\n",
    "from experiments.exp2_below_phoneme_clustering.kmeans.kmeans import KMeans\n",
    "from experiments.exp2_below_phoneme_clustering.kmeans.method import *\n",
    "from experiments.helpers.experiment_helpers import *\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "c55fb8b6",
   "metadata": {},
   "source": [
    "#### Data\n",
    "Collect the training dataset.\n",
    "It is restricted to 50 speakers of equal male-female distributions and only contains \"SX\" (phonetically diverse) sentences. The data are pre-processed into 10 steps long 14-mffc signals with 39 phoneme labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save = True\n",
    "\n",
    "data_path = '../../../'\n",
    "cache_dir = '../../cache/'\n",
    "dl = DataLoader(data_path, cache_dir)\n",
    "\n",
    "dr = []\n",
    "descriptions = dl.read_descriptions(\"Train\")\n",
    "descriptions['gender'] = descriptions.speaker_id.str[0]\n",
    "descriptions = descriptions.groupby(\"speaker_id\").first().reset_index() # Remove duplicate speakers\n",
    "descriptions = descriptions.groupby([\"dialect_region\", \"gender\"]).sample(4, replace=False).reset_index() #get 4 Males and 4 Females from each dr\n",
    "speakers = descriptions.speaker_id.values\n",
    "sentence = \"SX\"\n",
    "\n",
    "XorZ = \"X\"\n",
    "long_version = False\n",
    "n_mels = 14\n",
    "delta = False\n",
    "delta_delta = False\n",
    "subsamples = 10\n",
    "const_params = {\n",
    "    \"n_mels\":n_mels,\n",
    "    \"XorZ\":XorZ,\n",
    "    \"N\":100\n",
    "}\n",
    "\n",
    "path_option = \"Final\"+str(long_version)+str(n_mels)+str(delta)+str(delta_delta)+str(subsamples)\n",
    "\n",
    "if dr:\n",
    "    path_option = str(dr)+path_option\n",
    "if len(speakers):\n",
    "    path_option = str(len(speakers))+path_option\n",
    "if sentence:\n",
    "    path_option = sentence+path_option\n",
    "\n",
    "features,labels,oversamplings = dl.collectFeaturesInSegments(\n",
    "    n_mels=n_mels,delta=delta,delta_delta=delta_delta,\n",
    "    long_version=long_version,speakers=speakers,dr=dr,\n",
    "    sentence=sentence,subsamples=subsamples,path_option=path_option)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "11cebfd6",
   "metadata": {},
   "source": [
    "Regroup data and label arrays into a phoneme-keyed dictionary. Then, select only a subset of the phonemes and randomly sample them down to an equal number samples per phoneme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.data_processing import *\n",
    "\n",
    "#selected_labels = None\n",
    "#selected_labels = [\"aa\", \"b\", \"s\", \"iy\", \"f\", \"p\", \"g\"]\n",
    "\n",
    "selected_labels = [\"aa\", \"b\", \"s\", \"iy\", \"f\", \"p\", \"g\", \"r\", \"w\"]\n",
    "#selected_labels = [\"aa\", \"ae\", \"ah\", \"eh\", \"ih\", \"iy\", \"uh\"]\n",
    "#selected_labels = ['ih', 'r', 'uh', 'eh', 'l', 'ae', 'er', 'aa', 'aw', 'iy', 'ey', 'oy', 'ah', 'y']\n",
    "\n",
    "minn = 20\n",
    "\n",
    "phonemes, features, labels, features_test, labels_test = filter_data(features, labels, selected_labels=selected_labels, limit=minn, test=True)\n",
    "group = group_by_labels(features, labels)\n",
    "n_samples = len(features)\n",
    "n_classes = len(phonemes)\n",
    "\n",
    "correct_assignments = [ [] for _ in range(n_classes) ]\n",
    "idx = 0\n",
    "for i, phoneme in enumerate(group.keys()):\n",
    "    for _ in group[phoneme]:\n",
    "        correct_assignments[i].append(idx)\n",
    "        idx += 1\n",
    "\n",
    "print(f\"{str(len(features_test))} test samples\")\n",
    "print(f\"{str(n_classes)} phonemes: {phonemes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819aacae",
   "metadata": {},
   "source": [
    "#### Experiments pre-steps\n",
    "Initialize the ESN with the parameters found in experiment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "XorZ = \"X\"\n",
    "\n",
    "esn_params = {\n",
    "    \"in_dim\": n_mels*(1+delta+delta_delta),\n",
    "    \"out_dim\": n_mels*(1+delta+delta_delta),\n",
    "    \"N\": 100,\n",
    "    \"W_in_scale\": 1.1,\n",
    "    \"b_scale\": .6,\n",
    "    \"spectral_radius\": 2.57,\n",
    "    \"weights\": .1\n",
    "}\n",
    "\n",
    "esn = ESN(esn_params)\n",
    "\n",
    "esn_states = [ esn.run(feature.T, XorZ=XorZ) for feature in features ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d291400",
   "metadata": {},
   "source": [
    "Compute a conceptor for each sample.\n",
    "Currently, these are used for clustering only in the condition that uses conceptor similarity as the distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51007d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "aperture = \"auto\"\n",
    "normalize = True\n",
    "\n",
    "Cs = compute_Cs(signals=features, esn=esn, aperture=aperture, normalize=normalize, XorZ=XorZ, cache=save, file_identifier=path_option)\n",
    "target_sum = np.mean([sum_of_singular_vals(C) for C in Cs])\n",
    "print(target_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b603ee7",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32700c44",
   "metadata": {},
   "source": [
    "##### Single run\n",
    "An example run with the similarity-based condition and random initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#method = Method.CONCEPTOR_SIM\n",
    "#method = Method.STATE_EUCLIDIAN\n",
    "#method = Method.SIGNALS_EUCLIDIAN\n",
    "method = Method.CONCEPTOR_PRED\n",
    "#method = Method.CONCEPTOR_FROB\n",
    "#method = Method.CONCEPTOR_SPECTRAL\n",
    "#method = Method.PRED_CENTROIDS\n",
    "\n",
    "import importlib\n",
    "import experiments.exp2_below_phoneme_clustering.kmeans.kmeans\n",
    "importlib.reload(experiments.exp2_below_phoneme_clustering.kmeans.kmeans)\n",
    "from experiments.exp2_below_phoneme_clustering.kmeans.kmeans import KMeans\n",
    "\n",
    "nb_clusters = len(selected_labels)\n",
    "\n",
    "km = KMeans(method, Cs=Cs, signals=features, esn_states=esn_states, XorZ=XorZ, target_sum=target_sum)\n",
    "\n",
    "centroids, clusters, ds_hist, cluster_hist, centroid_hist = km.k_means(nb_clusters=nb_clusters, max_epochs=100, init_clusters=\"random\", save=False, debug=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluation of the single run:\n",
    "\n",
    "1. The Normalized Mutual Information (NMI) for evaluating how well clusters matched the original classes on a range between 0 (no overlaps) and 1 (perfect match)\n",
    "2. The (Simplified) Silhouette Coefficient (SC) for evaluating the cohesiveness of the clusters, i.e., the mean difference between intra-cluster and inter-cluster distances, on a range between -1 and 1, where a high value corresponds to highly cohesive clusters.\n",
    "\n",
    "Caution for interpretation: The SC is dependent on the distance function for its computation potentially prioritizing some distance functions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converting the clusters to an index-based representation\n",
    "assignment_hist = km.cluster_to_assignment_repr_l(cluster_hist)\n",
    "assignments_kmeans = assignment_hist[-1]\n",
    "\n",
    "# Ground truth\n",
    "print('--------------truth--------------')\n",
    "correct_clusters = km.assignment_to_cluster_repr(correct_assignments)\n",
    "nmi_truth = NMI(correct_assignments, correct_assignments)\n",
    "\n",
    "acc_truth = clas_acc(correct_clusters, correct_clusters, phonemes, features_test, labels_test)\n",
    "print(f'Test Accuracy Dataset     : {acc_truth}')\n",
    "print(\"Dataset NMI: \", nmi_truth)\n",
    "print(\"Dataset Lengths: \", [len(x) for x in correct_assignments])\n",
    "\n",
    "# Kmeans\n",
    "print('--------------kmeans--------------')\n",
    "nmi_kmeans = NMI(assignments_kmeans, correct_assignments)\n",
    "acc_kmeans = clas_acc(clusters, correct_clusters, phonemes, features_test, labels_test)\n",
    "print(f'Test Accuracy Kmeans     : {acc_kmeans}')\n",
    "\n",
    "print(\"Kmeans NMI: \", nmi_kmeans)\n",
    "print(\"Kmeans Lengths: \", [len(x) for x in assignments_kmeans])\n",
    "\n",
    "# Random\n",
    "print('--------------random--------------')\n",
    "clusters_random = km.init_random(len(clusters))\n",
    "assignments_random = km.cluster_to_assignment_repr(clusters_random)\n",
    "nmi_baseline = NMI(assignments_random, correct_assignments)\n",
    "acc_baseline = clas_acc(clusters_random, correct_clusters, phonemes, features_test, labels_test)\n",
    "\n",
    "print(f'Test Accuracy random     : {acc_baseline}')\n",
    "print(\"Baseline NMI: \", nmi_baseline)\n",
    "print(\"Baseline Lengths: \", [len(x) for x in assignments_random])\n",
    "\n",
    "NMI_list = NMIs_from_list(assignment_hist, correct_assignments)\n",
    "acc_list = clas_acc_from_list(cluster_hist, correct_clusters, phonemes, features_test, labels_test)\n",
    "\n",
    "def plot_progress(NMI_list, acc_list, title=''):\n",
    "    plt.figure()\n",
    "    plt.plot(NMI_list, color=\"orange\", label=\"Kmeans NMI\")\n",
    "    plt.axhline(y=nmi_baseline, color='orange', linestyle='dashdot', label=\"Baseline NMI\")\n",
    "    plt.axhline(y=nmi_truth, color='orange', linestyle='dashed', label=\"Dataset NMI\")\n",
    "    plt.plot(acc_list, color=\"blue\", label=\"Kmeans acc\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Iteration', fontsize=14)\n",
    "    plt.ylabel('Score (NMI and acc)', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "plot_progress(NMI_list, acc_list, title=\"Acc and NMI for Kmeans with random initialization and (inversed) conceptor similarity distance function\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Comparative Experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def experiment(repetitions=2, cluster_numbers=[n_classes]):\n",
    "    params = {\n",
    "        \"method\" : [Method.SIGNALS_EUCLIDIAN, Method.STATE_EUCLIDIAN, Method.CONCEPTOR_PRED, Method.PRED_CENTROIDS, Method.CONCEPTOR_PRED_CS_ONLY],\n",
    "        \"init_clusters\" : [\"smart\", \"random\"]\n",
    "    }\n",
    "    results = []\n",
    "    for method in params[\"method\"]:\n",
    "        for init in params[\"init_clusters\"]:\n",
    "            for n_clusters in cluster_numbers:\n",
    "                NMIs = []\n",
    "                accs = []\n",
    "                ds = []\n",
    "                print(f\"Method: {method}, Cluster initialization: {init}, #clusters: {n_clusters}\")\n",
    "                for _ in range(repetitions):\n",
    "                    km = KMeans(method, Cs=Cs, signals=features, esn_states=esn_states, XorZ=XorZ, target_sum=target_sum)\n",
    "                    centroids, clusters, ds_hist, cluster_hist,_ = km.k_means(\n",
    "                        nb_clusters=n_clusters, max_epochs=100, init_clusters=init, save=False, debug=False\n",
    "                    )\n",
    "                    assignment_hist = [ km.cluster_to_assignment_repr(cluster) for cluster in cluster_hist ]\n",
    "\n",
    "                    # Results\n",
    "                    NMIs.append(NMIs_from_list(assignment_hist, correct_assignments))\n",
    "                    accs.append(clas_acc_from_list(cluster_hist, correct_clusters, phonemes, features_test, labels_test))\n",
    "                    ds.append(km.intra_dist_mean_from_list(cluster_hist))\n",
    "\n",
    "                results.append( {\n",
    "                    \"method\": method,\n",
    "                    \"init_clusters\": init,\n",
    "                    \"n_clusters\": n_clusters,\n",
    "                    \"NMIs\": NMIs,\n",
    "                    \"mean_NMI\": np.mean([ n[-1] for n in NMIs ]),\n",
    "                    \"accs\": accs,\n",
    "                    \"mean_acc\": np.mean([ a[-1] for a in accs ]),\n",
    "                    \"ds\": ds,\n",
    "                    \"mean_ds\": np.mean([ d[-1] for d in ds ])\n",
    "                } )\n",
    "    return results\n",
    "\n",
    "cluster_numbers = range(1, 18, 1)\n",
    "results = experiment(repetitions=15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Extract the NMIs and SCs from the results for display."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nmis = {}\n",
    "accs = {}\n",
    "ds = {}\n",
    "nmis_runs = {}# runs with correct number of classes\n",
    "accs_runs = {}\n",
    "ds_runs = {}\n",
    "\n",
    "def trial_name(result):\n",
    "    return result[\"method\"].name + \" \" + result[\"init_clusters\"]\n",
    "\n",
    "for entry in results:\n",
    "    name = trial_name(entry)\n",
    "    if name not in nmis.keys():\n",
    "        nmis[name] = []\n",
    "        accs[name] = []\n",
    "        ds[name] = []\n",
    "        nmis_runs[name] = []\n",
    "        accs_runs[name] = []\n",
    "        ds_runs[name] = []\n",
    "    nmis[name].append(entry[\"mean_NMI\"])\n",
    "    accs[name].append(entry[\"mean_acc\"])\n",
    "    ds[name].append(entry[\"mean_ds\"])\n",
    "    if entry[\"n_clusters\"] == n_classes:\n",
    "        nmis_runs[name] += entry[\"NMIs\"]\n",
    "        accs_runs[name] += entry[\"accs\"]\n",
    "        ds_runs[name] += entry[\"ds\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the best results and plot the scores by cluster number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_NMIs = Plot()\n",
    "# plot_NMIs.inc(ylabel=\"NMI score\", xlabel=\"k clusters\")\n",
    "# plot_accs = Plot()\n",
    "# plot_accs.inc(ylabel=\"SC score\", xlabel=\"k clusters\")\n",
    "cluster_numbers = [n_classes]\n",
    "\n",
    "print(\"Mean NMI scores:\")\n",
    "for name, nmi in nmis.items():\n",
    "    print(f\"{name}: {np.mean(nmi)} at k={cluster_numbers[np.argmax(nmi)]} clusters\")\n",
    "#     plot_NMIs.add(nmi,x=cluster_numbers, label=name)\n",
    "# print(\"Random clusters:\", nmi_baseline)\n",
    "# print(\"Dataset: \", nmi_truth)\n",
    "\n",
    "print(\"Mean ACC:\")\n",
    "for name, acc in accs.items():\n",
    "    print(f\"{name}: {np.mean(acc)} at k={cluster_numbers[np.argmax(acc)]} clusters\")\n",
    "    # plot_accs.add(acc,x=cluster_numbers, label=name)\n",
    "# print(\"Random clusters:\", acc_baseline)\n",
    "# print(\"Dataset SC: \", acc_truth)\n",
    "# plot_NMIs.finalize(\"NMIs for different k's across conditions\")\n",
    "# plot_accs.finalize(\"NMIs for different k's across conditions\")\n",
    "print(\"Mean D:\")\n",
    "for name, d in ds.items():\n",
    "    print(f\"{name}: {np.mean(d)} at k={cluster_numbers[np.argmax(d)]} clusters\")\n",
    "    # plot_accs.add(acc,x=cluster_numbers, label=name)\n",
    "# print(\"Random clusters:\", acc_baseline)\n",
    "# print(\"Dataset SC: \", acc_truth)\n",
    "# plot_NMIs.finalize(\"NMIs for different k's across conditions\")\n",
    "# plot_accs.finalize(\"NMIs for different k's across conditions\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot progress over kmeans iterations with k=7 clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: SEPARATE PLOTS\n",
    "title=\"NMI progress for Kmeans with k=7 clusters.\"\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "#names = [\"Control\", \"Conceptor\"]\n",
    "# SCs\n",
    "for (name, nmis_run) in nmis_runs.items():\n",
    "    for nmis_r in nmis_run:\n",
    "        plt.plot(nmis_r, label=\"Kmeans: \"+name)\n",
    "plt.axhline(y=nmi_baseline, color='black', linestyle='dashdot', label=\"Random\")\n",
    "plt.axhline(y=nmi_truth, color='green', linestyle='dashed', label=\"Dataset\")\n",
    "\n",
    "# Legend\n",
    "plt.legend(title=\"NMI\", title_fontsize=16, fontsize=16)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('NMI', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: SEPARATE PLOTS\n",
    "title=\"ACC Progress with K=7 Clusters.\"\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "#names = [\"Control\", \"Conceptor\"]\n",
    "# SCs\n",
    "for (name, accs_run) in accs_runs.items():\n",
    "    for accs_r in accs_run:\n",
    "        plt.plot(accs_r, label=\"Kmeans: \"+name)\n",
    "plt.axhline(y=acc_baseline, color='black', linestyle='dashdot', label=\"Random\")\n",
    "plt.axhline(y=acc_truth, color='green', linestyle='dashed', label=\"Dataset\")\n",
    "\n",
    "# Legend\n",
    "plt.legend(title=\"SC\", title_fontsize=16, fontsize=16)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('SC', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "title=\"D Progress with K=7 Clusters.\"\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "#names = [\"Control\", \"Conceptor\"]\n",
    "for (name, ds_run) in ds_runs.items():\n",
    "    for ds_r in ds_run:\n",
    "        plt.plot(ds_r, label=\"Kmeans: \"+name)\n",
    "\n",
    "# Legend\n",
    "plt.legend(title=\"D\", title_fontsize=16, fontsize=16)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('D', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title=\"ACC Progress with K=7 Clusters.\"\n",
    "plt.figure(figsize=(14,12))\n",
    "\n",
    "names = [\"Control\", \"Conceptor\"]\n",
    "# SCs\n",
    "max_len = max(max(len(accs_r) for accs_r in accs_run) for name, accs_run in accs_runs.items())  # find the longest sequence\n",
    "for name, accs_run in accs_runs.items():\n",
    "    # Pad sequences with NaNs\n",
    "    padded_accs = [np.pad(accs_r, (0, max_len - len(accs_r)), constant_values=np.nan) for accs_r in accs_run]\n",
    "    # Compute average\n",
    "    avg_accs = np.nanmean(padded_accs, axis=0)\n",
    "    plt.plot(avg_accs, label=\"Kmeans: \"+name)\n",
    "plt.axhline(y=acc_baseline, color='black', linestyle='dashdot', label=\"Random\")\n",
    "plt.axhline(y=acc_truth, color='green', linestyle='dashed', label=\"Dataset\")\n",
    "\n",
    "# Legend\n",
    "plt.legend(title=\"SC\", title_fontsize=16, fontsize=16)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('SC', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title=\"NMI Progress with K=7 Clusters.\"\n",
    "plt.figure(figsize=(14,12))\n",
    "\n",
    "names = [\"Control\", \"Conceptor\"]\n",
    "# SCs\n",
    "max_len = max(max(len(nmis_r) for nmis_r in nmis_run) for name, nmis_run in nmis_runs.items())  # find the longest sequence\n",
    "for name, nmis_run in nmis_runs.items():\n",
    "    # Pad sequences with NaNs\n",
    "    padded_nmis = [np.pad(nmis_r, (0, max_len - len(nmis_r)), constant_values=np.nan) for nmis_r in nmis_run]\n",
    "    # Compute average\n",
    "    avg_nmis = np.nanmean(padded_nmis, axis=0)\n",
    "    plt.plot(avg_nmis, label=\"Kmeans: \"+name)\n",
    "plt.axhline(y=nmi_baseline, color='black', linestyle='dashdot', label=\"Random\")\n",
    "plt.axhline(y=nmi_truth, color='green', linestyle='dashed', label=\"Dataset\")\n",
    "\n",
    "# Legend\n",
    "plt.legend(title=\"NMI\", title_fontsize=16, fontsize=16)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('NMI', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "title=\"D Progress with K=7 Clusters.\"\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "names = [\"Control\", \"Conceptor\"]\n",
    "# SCs\n",
    "max_len = max(max(len(ds_r) for ds_r in ds_run) for name, ds_run in ds_runs.items())  # find the longest sequence\n",
    "for name, ds_run in ds_runs.items():\n",
    "    # Pad sequences with NaNs\n",
    "    padded_ds = [np.pad(dsx_r, (0, max_len - len(ds_r)), constant_values=np.nan) for ds_r in ds_run]\n",
    "    # Compute average\n",
    "    avg_ds = np.nanmean(padded_ds, axis=0)\n",
    "    plt.plot(avg_ds, label=\"Kmeans: \"+name)\n",
    "\n",
    "# Legend\n",
    "plt.legend(title=\"SC\", title_fontsize=16, fontsize=16)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('SC', fontsize=16)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "85a7095e0b17f1db0bd51573cd0d88781c688ef4e6e2f1ecf40c28cdd364372d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
