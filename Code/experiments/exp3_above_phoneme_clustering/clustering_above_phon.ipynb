{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hierarchical agglomerative clustering (Above-phoneme)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import libraries and helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "directory = os.path.abspath('/Users/joris/Documents/Work/bsc ai/bt/Bachelor-Thesis/code')\n",
    "sys.path.append(directory)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from lib.esn import ESN\n",
    "from dataset.loading import DataLoader\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data\n",
    "Collect the TIMIT training dataset. The data are pre-processed into 10 steps long 14-mffc signals with 39 phoneme labels/classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-from output\n",
      "---- success\n"
     ]
    }
   ],
   "source": [
    "path = '../../data/'\n",
    "fc = DataLoader(path)\n",
    "\n",
    "dr = []\n",
    "speakers = []\n",
    "XorZ = \"X\"\n",
    "long_version = False\n",
    "n_mels = 13\n",
    "delta = False\n",
    "delta_delta = False\n",
    "subsamples = 10\n",
    "\n",
    "path_option = \"Final\"+str(long_version)+str(n_mels)+str(delta)+str(delta_delta)+str(subsamples)\n",
    "\n",
    "if dr:\n",
    "    path_option = str(dr)+\"_\"+path_option\n",
    "if len(speakers):\n",
    "    path_option = str(speakers[0])+\"_\"+path_option\n",
    "\n",
    "features, labels, _ = fc.collectFeaturesInSegments(\n",
    "    n_mels=n_mels, delta=delta, delta_delta=delta_delta,\n",
    "    long_version=long_version, speakers=speakers, dr=dr,\n",
    "    subsamples=subsamples, path_option=path_option)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regroup data and label arrays into a phoneme-keyed dictionary. All phonemes are used, but for debugging a subset may be selected."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d56f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 177080 samples of shape (10, 14)\n"
     ]
    }
   ],
   "source": [
    "from dataset.data_processing import *\n",
    "\n",
    "selected_labels = None # No filtering is applied\n",
    "#selected_labels = [\"aa\", \"b\", \"s\", \"iy\", \"uh\"]\n",
    "#selected_labels = [\"aa\", \"ae\", \"ah\", \"eh\", \"ih\", \"iy\", \"uh\"]\n",
    "#selected_labels = [\"aa\", \"ae\", \"ah\", \"eh\", \"ih\", \"iy\", \"uh\", \"er\", \"ey\", \"ix\", \"aw\", \"axr\", \"l\", \"oy\", \"r\", \"y\"]\n",
    "\n",
    "phonemes, features, labels = filter_and_downsample(features, labels, selected_labels=selected_labels, limit=None)\n",
    "group = group_by_labels(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clustering experiment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Compute conceptors, one per phoneme\n",
    "The ESN parameters were chosen by hand."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14462e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing conceptors...\n"
     ]
    }
   ],
   "source": [
    "# Init reservoir\n",
    "esn_params = {\n",
    "    \"in_dim\": n_mels,\n",
    "    \"out_dim\": n_mels,\n",
    "    \"N\": 100,\n",
    "    \"W_in_scale\": 1.1,\n",
    "    \"b_scale\": .6,\n",
    "    \"spectral_radius\": 2.57,\n",
    "    \"weights\": .1\n",
    "}\n",
    "\n",
    "esn = ESN(esn_params)\n",
    "\n",
    "# Compute conceptors\n",
    "from experiments.helpers.experiment_helpers import *\n",
    "\n",
    "aperture = \"auto\"\n",
    "normalize = True\n",
    "Cs = compute_Cs(group=group, esn=esn, aperture=aperture, normalize=normalize, XorZ=XorZ, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Compute heatmap\n",
    "Compute the mutual similarities between every two phoneme conceptors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432642e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from lib.clustering.clustering_metrics import *\n",
    "\n",
    "save = True\n",
    "hm = None\n",
    "hm_filename = str(selected_labels)+path_option+XorZ + str(aperture) + str(esn.esn_params) + str(len(group.keys())) + str(len(list(group.values())[0])) + \"heatmap\"\n",
    "\n",
    "if save:\n",
    "    hm = try_reading_from_cache(hm_filename)\n",
    "if hm is None:\n",
    "    print(\"- computing heatmap\")\n",
    "    hm = get_heat_map(Cs, similarity_c)\n",
    "    save_to_cache(hm_filename, hm)\n",
    "    print(\"--- Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Perform average linkage of phoneme conceptors and plot results\n",
    "Therefore, the similarities in the heat map are converted to distances."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sc\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "distArray = ssd.squareform(hm)\n",
    "distArray = 1-distArray\n",
    "link = sc.linkage(distArray, method='average', optimal_ordering=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4. Plotting\n",
    "Plot the resulting dendrogram"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "ax.grid(False)\n",
    "ax.set_facecolor('white')\n",
    "D = sc.dendrogram(link,labels=phonemes,orientation='right',distance_sort=False)\n",
    "\n",
    "plt.ylabel('Phonemic Class',fontsize=15)\n",
    "plt.xlabel(r\"Dissimilarity\",fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the similarity heatmap on which basis the distances were computed that were used for clustering. The marked groups are, from top-left to bottom-right, vowels, mixed, nasals, affricatives, and stops"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0ae15",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "np.fill_diagonal(hm, 1)\n",
    "\n",
    "labs = D[\"ivl\"]\n",
    "custom_labs = ['ah', 'uw', 'sh', 'iy', 'ih', 'eh', 'ae', 'aa', 'ey', 'ay', 'er', 'ow', 'oy', 'aw', 'uh',\n",
    "               'l', 'r', 'w', 'y', 'hh', 'h#',\n",
    "               'm', 'n', 'ng',\n",
    "               's', 'z', 'f', 'v', 'th', 'dh',\n",
    "               'jh', 'ch',\n",
    "               'b', 'd', 'g', 'k', 'p', 't', 'dx']\n",
    "\n",
    "reorder = [ labs.index(lab) for lab in custom_labs]\n",
    "hm = hm[reorder,:]\n",
    "hm = hm[:,reorder]\n",
    "\n",
    "plt.figure(figsize=(17,15),dpi=100)\n",
    "sns.set_theme()\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "ax_hm = sns.heatmap(hm, xticklabels=custom_labs, yticklabels=custom_labs, linewidths=.5, center=np.mean(hm)-.05)\n",
    "plt.rc('xtick', labelsize='20')    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize='20')\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# # Adding coloring to phonetic groups\n",
    "# recs = [\n",
    "#     [0,15],\n",
    "#     [15,6],\n",
    "#     [21,3],\n",
    "#     [24,6],\n",
    "#     [30,2],\n",
    "#     [32,7]\n",
    "# ]\n",
    "# for rec in recs:\n",
    "#     ax_hm.add_patch(\n",
    "#          patches.Rectangle(\n",
    "#              (rec[0], rec[0]),\n",
    "#              rec[1], rec[1],\n",
    "#              edgecolor='blue',\n",
    "#              fill=False,\n",
    "#              lw=4\n",
    "#          )\n",
    "#     )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
