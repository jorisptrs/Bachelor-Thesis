{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b2514c",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb8b6",
   "metadata": {},
   "source": [
    "Import libraries and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "directory = os.path.abspath('/Users/joris/Documents/Work/bsc ai/bt/Bachelor-Thesis/code')\n",
    "sys.path.append(directory)\n",
    "\n",
    "from classifier import Classifier\n",
    "from env_variables import *\n",
    "from dataset.loading import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data\n",
    "Collect the complete TIMIT training dataset. The data are pre-processed into 10 steps long 14-mffc signals with 39 phoneme labels/classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e86d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-from output\n",
      "---- success\n"
     ]
    }
   ],
   "source": [
    "data_path = '../../../'\n",
    "cache_dir = '../../cache/'\n",
    "dl = DataLoader(data_path, cache_dir)\n",
    "\n",
    "dr = []\n",
    "speakers = []\n",
    "long_version = False\n",
    "n_mels = 14\n",
    "delta = False\n",
    "delta_delta = False\n",
    "subsamples = 10\n",
    "\n",
    "path_option = \"Final\"+str(long_version)+str(n_mels)+str(delta)+str(delta_delta)+str(subsamples)\n",
    "\n",
    "if dr:\n",
    "    path_option = str(dr)+path_option\n",
    "if len(speakers):\n",
    "    path_option = str(len(speakers))+path_option\n",
    "\n",
    "features_train, labels_train, _ = dl.collectFeaturesInSegments(\n",
    "    n_mels=n_mels, delta=delta, delta_delta=delta_delta,\n",
    "    long_version=long_version, speakers=speakers, dr=dr,\n",
    "    subsamples=subsamples, path_option=path_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cebfd6",
   "metadata": {},
   "source": [
    "Regroup data and label arrays into a phoneme-keyed dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d56f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 177080 samples of shape (10, 14)\n"
     ]
    }
   ],
   "source": [
    "from dataset.data_processing import *\n",
    "\n",
    "phonemes, features_train, labels_train = filter_data(features_train, labels_train, limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a2ec9",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Largely following the method presented by Jaeger (2014).\n",
    "The ESN parameters were chosen by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 177080\n",
      "- computing conceptors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m clas \u001B[38;5;241m=\u001B[39m Classifier(W_in_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.1\u001B[39m,\n\u001B[1;32m      2\u001B[0m                  b_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.6\u001B[39m,\n\u001B[1;32m      3\u001B[0m                  spectral_radius\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2.57\u001B[39m,\n\u001B[1;32m      4\u001B[0m                  weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m.1\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m _ \u001B[38;5;241m=\u001B[39m \u001B[43mclas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn_mels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_mels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mXorZ\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msave\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     11\u001B[0m \u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/exp1_classification/classifier.py:53\u001B[0m, in \u001B[0;36mClassifier.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m     43\u001B[0m esn_params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_mels,\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_mels,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights\n\u001B[1;32m     51\u001B[0m }\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mesn \u001B[38;5;241m=\u001B[39m ESN(esn_params)\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCs_clas, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mNs_clas \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_Cs_and_Ns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mesn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mesn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maperture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXorZ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Return the classifier\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/helpers/experiment_helpers.py:12\u001B[0m, in \u001B[0;36mcompute_Cs_and_Ns\u001B[0;34m(group, esn, aperture, normalize, XorZ, cache)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_Cs_and_Ns\u001B[39m(group, esn, aperture\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, XorZ\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m---> 12\u001B[0m     Cs \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_Cs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mesn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mesn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maperture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maperture\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mXorZ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- computing negative conceptors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m     Ns \u001B[38;5;241m=\u001B[39m Ns_from_Cs(Cs)\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/helpers/experiment_helpers.py:66\u001B[0m, in \u001B[0;36mcompute_Cs\u001B[0;34m(group, signals, esn, aperture, normalize, XorZ, cache, file_identifier)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, signals \u001B[38;5;129;01min\u001B[39;00m group\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 66\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[43mrun_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mesn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msignals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m aperture \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     68\u001B[0m             Cs\u001B[38;5;241m.\u001B[39mappend(compute_c(X, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/helpers/experiment_helpers.py:87\u001B[0m, in \u001B[0;36mrun_all\u001B[0;34m(esn, signals, XorZ)\u001B[0m\n\u001B[1;32m     85\u001B[0m X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([])\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m signal \u001B[38;5;129;01min\u001B[39;00m signals:\n\u001B[0;32m---> 87\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mesn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43msignal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mXorZ\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m     X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack((X, x)) \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39msize \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/lib/esn.py:95\u001B[0m, in \u001B[0;36mESN.run\u001B[0;34m(self, signal, XorZ)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     94\u001B[0m     p \u001B[38;5;241m=\u001B[39m signal[:, t]\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_dim, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m---> 95\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtanh(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_in, p) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb)\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m XorZ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mZ\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     97\u001B[0m     X[t \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN \u001B[38;5;241m+\u001B[39m signal\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):t \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN \u001B[38;5;241m+\u001B[39m signal\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m p\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]] \u001B[38;5;241m=\u001B[39m p\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "clas = Classifier(W_in_scale=1.1,\n",
    "                 b_scale=.6,\n",
    "                 spectral_radius=2.57,\n",
    "                 weights=.1)\n",
    "\n",
    "_ = clas.fit(features_train, labels_train, **{\n",
    "    \"n_mels\": n_mels,\n",
    "    \"XorZ\": \"X\",\n",
    "    \"N\": 100,\n",
    "    \"save\": True\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Testing\n",
    "Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-from output\n",
      "---- success\n",
      "Filtered to 64145 samples of shape (10, 14)\n"
     ]
    }
   ],
   "source": [
    "features_test, labels_test, _ = dl.collectFeaturesInSegments(\n",
    "    ft='Test',n_mels=n_mels,delta=delta,delta_delta=delta_delta,\n",
    "    long_version=long_version,speakers=[],dr=dr,sentence=[],\n",
    "    subsamples=subsamples,path_option=path_option+\"_test\")\n",
    "\n",
    "_, features_test, labels_test = filter_data(features_test, labels_test, limit=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of x : 0.561638807318726\n",
      "Test Accuracy of x     : 0.5604022137345077\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy of x : {clas.score(features_train, labels_train)}')\n",
    "print(f'Test Accuracy of x     : {clas.score(features_test, labels_test)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct a Confusion Matrix to distinguish between classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "phonemes_in_order = ['ah', 'uw', 'sh', 'iy', 'ih', 'eh', 'ae', 'aa', 'ey', 'ay', 'er', 'ow', 'oy', 'aw', 'uh',\n",
    "               'l', 'r', 'w', 'y', 'hh', 'h#',\n",
    "               'm', 'n', 'ng',\n",
    "               's', 'z', 'f', 'v', 'th', 'dh',\n",
    "               'jh', 'ch',\n",
    "               'b', 'd', 'g', 'k', 'p', 't', 'dx']\n",
    "\n",
    "\n",
    "labels_pred = clas.predict(features_test)\n",
    "cm = confusion_matrix(labels_test, labels_pred, labels=phonemes_in_order, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=phonemes)\n",
    "fig, ax = plt.subplots(figsize=(14,11.5))\n",
    "\n",
    "disp.plot(ax=ax, include_values=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extras\n",
    "\n",
    "#### Z-Classification: Including the input signals into the conceptors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 177080\n",
      "- computing conceptors\n",
      "optimizing\n",
      "Computing gammas...\n",
      "Optimal gamma:  477.34873516437597\n",
      "normalizing\n",
      "Target:  228.93113558697223\n",
      "std 12.886582665462866\n",
      "- computing negative conceptors\n",
      "Training Accuracy of z : 0.6364016263835555\n",
      "Test Accuracy of z     : 0.4913243432847455\n"
     ]
    }
   ],
   "source": [
    "clas2 = Classifier(1.5, .2, 1.5, .1) # Z optimal params\n",
    "\n",
    "clas2.fit(features_train, labels_train, **{\n",
    "    \"n_mels\":n_mels,\n",
    "    \"XorZ\":\"Z\",\n",
    "    \"N\":40,\n",
    "    \"save\":True\n",
    "})\n",
    "\n",
    "print(f'Training Accuracy of z : {clas2.score(features_train, labels_train)}')\n",
    "print(f'Test Accuracy of z     : {clas2.score(features_test, labels_test)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bayesian Hyperparameter Tuning\n",
    "Running this is only feasible with small ESNs (<40 neurons)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train,\n",
    "                                                    labels_train,\n",
    "                                                    stratify = labels_train,\n",
    "                                                    random_state = 1)\n",
    "\n",
    "# Bayesian Optimization wrapper\n",
    "def objective_function(W_in_scale,\n",
    "                       b_scale,\n",
    "                       spectral_radius,\n",
    "                       weights):\n",
    "\n",
    "    model = Classifier(W_in_scale,\n",
    "                 b_scale,\n",
    "                 spectral_radius,\n",
    "                 weights)\n",
    "    model.fit(X_train, y_train, **{\n",
    "        \"n_mels\": n_mels,\n",
    "        \"XorZ\": \"X\",\n",
    "        \"N\": 100\n",
    "    })\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'W_in_scale': [.01, 2],\n",
    "    'spectral_radius': [0.01, 4],\n",
    "    'b_scale': [0, 2],\n",
    "    'weights': [.01,1]\n",
    "}\n",
    "\n",
    "# Bayesian optimization of the objective function.\n",
    "optimizer = BayesianOptimization(f = objective_function,\n",
    "                                 pbounds = parameters,\n",
    "                                 random_state = 0)\n",
    "optimizer.maximize(init_points = 10, n_iter = 100)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(f\"Best parmaters: {best_params}; f(x) = {optimizer.max['target']}.\")\n",
    "\n",
    "\n",
    "# Scikitlearn\n",
    "#opt = Classifier()\n",
    "#opt = BayesSearchCV(Classifier(), parameters, n_iter=50, cv=3)\n",
    "#opt.fit(features, labels, **{\n",
    "#   \"in_dim\":n_mels,\n",
    "#   \"out_dim\":n_mels\n",
    "#})\n",
    "#print(opt.score(fv, lv))\n",
    "#print(opt.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the tuning progress"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "_, ax1 = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Scores:\n",
    "ax1.plot(range(1, 1 + len(optimizer.space.target)), optimizer.space.target, color='r', label=\"Accuracy - $f(\\\\rho$, $k_{W^in}$, $k_b$, $r$)\")\n",
    "\n",
    "# Parameters\n",
    "W_in_scale = []\n",
    "b_scale = []\n",
    "spectral_radius = []\n",
    "weights = []\n",
    "\n",
    "for res in optimizer.res:\n",
    "    W_in_scale.append(res[\"params\"][\"W_in_scale\"])\n",
    "    b_scale.append(res[\"params\"][\"b_scale\"])\n",
    "    spectral_radius.append(res[\"params\"][\"spectral_radius\"])\n",
    "    weights.append(res[\"params\"][\"weights\"])\n",
    "\n",
    "if True:\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), W_in_scale, \"--\", label=\"$W^{in}$\")\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), b_scale, \"--\", label=\"$k_b$\")\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), spectral_radius, \"--\", label=\"$r$\")\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), weights, \"--\", label=\"$\\\\rho$\")\n",
    "\n",
    "ax1.set_xlabel('Iteration', fontsize = 20)\n",
    "ax1.set_ylabel('Accuracy', color=\"r\", fontsize = 20)\n",
    "ax2.set_ylabel('Hyperparameter value', fontsize = 20)\n",
    "\n",
    "ax1.legend(loc=\"upper left\", fontsize = 20)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
