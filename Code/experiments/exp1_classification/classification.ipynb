{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b2514c",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fb8b6",
   "metadata": {},
   "source": [
    "### Collect training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e86d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-from output\n",
      "---- success\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os, sys\n",
    "import warnings\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lib.esn import ESN\n",
    "from dataset.loading import DataLoader\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "directory = os.path.abspath('/Users/joris/Documents/Work/bsc ai/bt/Bachelor-Thesis/code')\n",
    "sys.path.append(directory)\n",
    "\n",
    "path = '../../dataset/'\n",
    "dl = DataLoader(path)\n",
    "\n",
    "dr = []\n",
    "speakers = []\n",
    "XorZ = \"X\"\n",
    "long_version = False\n",
    "n_mels = 14\n",
    "delta = False\n",
    "delta_delta = False\n",
    "subsamples = 10\n",
    "const_params = {\n",
    "    \"n_mels\":n_mels,\n",
    "    \"XorZ\":XorZ\n",
    "}\n",
    "\n",
    "path_option = \"Final\"+str(long_version)+str(n_mels)+str(delta)+str(delta_delta)+str(subsamples)\n",
    "\n",
    "if dr:\n",
    "    path_option = str(dr)+\"_\"+path_option\n",
    "if len(speakers):\n",
    "    path_option = str(speakers[0])+\"_\"+path_option\n",
    "\n",
    "features_train, labels_train, _ = dl.collectFeaturesInSegments(\n",
    "    n_mels=n_mels, delta=delta, delta_delta=delta_delta,\n",
    "    long_version=long_version, speakers=speakers, dr=dr,\n",
    "    subsamples=subsamples, path_option=path_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cebfd6",
   "metadata": {},
   "source": [
    "### Regroup data and subset phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d56f220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 69807 samples of shape (10, 14)\n"
     ]
    }
   ],
   "source": [
    "from dataset.data_processing import *\n",
    "\n",
    "phonemes, features_train, labels_train = filter_data(features_train, labels_train, limit=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a2ec9",
   "metadata": {},
   "source": [
    "### Compute conceptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70fbab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.helpers.experiment_helpers import *\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class Classifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_in_scale,\n",
    "                 b_scale,\n",
    "                 spectral_radius,\n",
    "                 weights):\n",
    "        self.W_in_scale = W_in_scale\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.b_scale = b_scale\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y, **params):\n",
    "        self.n_mels = params[\"n_mels\"]\n",
    "        self.XorZ = params[\"XorZ\"]\n",
    "\n",
    "        # Group data by class\n",
    "        group = group_by_labels(X, y)\n",
    "\n",
    "        self.classes = list(group.keys())\n",
    "        self.n_samples = sum([len(x) for x in list(group.values())])\n",
    "\n",
    "        print(f\"Number of samples: {self.n_samples}\")\n",
    "        # Init Reservoir\n",
    "        esn_params = {\n",
    "            \"in_dim\": self.n_mels,\n",
    "            \"out_dim\": self.n_mels,\n",
    "            \"N\": 100,\n",
    "            \"W_in_scale\": self.W_in_scale,\n",
    "            \"b_scale\": self.b_scale,\n",
    "            \"spectral_radius\": self.spectral_radius,\n",
    "            \"weights\": self.weights\n",
    "        }\n",
    "        self.esn = ESN(esn_params)\n",
    "        self.Cs_clas, self.Ns_clas = compute_Cs_and_Ns(group, esn=self.esn, aperture=\"auto\", normalize=True, XorZ=self.XorZ, cache=False)\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        for sample in X:\n",
    "            x = self.esn.run(sample.T, XorZ=self.XorZ)\n",
    "            es = evidences_for_Cs(x,self.Cs_clas,self.Ns_clas)\n",
    "            if self.XorZ == \"X\":\n",
    "                es = [ np.sum(p) for p in es ]\n",
    "            y.append(self.classes[np.argmax(es)])\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 69807\n",
      "- computing conceptors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 29>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Old params:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#opt = Classifier(1.5, .2, 1.5, .1) # Z optimal params\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#opt = Classifier(1.1, .44, 2.57, .1 # X optimal params\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m#Training Accuracy of x : 0.5168305748780683\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m#Test Accuracy of x     : 0.5273209135552265\u001B[39;00m\n\u001B[1;32m     25\u001B[0m optx \u001B[38;5;241m=\u001B[39m Classifier(\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;241m1.1\u001B[39m, \u001B[38;5;241m.6\u001B[39m, \u001B[38;5;241m2.57\u001B[39m, \u001B[38;5;241m.1\u001B[39m\n\u001B[1;32m     27\u001B[0m )\n\u001B[0;32m---> 29\u001B[0m \u001B[43moptx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn_mels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mn_mels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mXorZ\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     32\u001B[0m \u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mClassifier.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m     28\u001B[0m esn_params \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_mels,\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mout_dim\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_mels,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweights\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights\n\u001B[1;32m     36\u001B[0m }\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mesn \u001B[38;5;241m=\u001B[39m ESN(esn_params)\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mCs_clas, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mNs_clas \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_Cs_and_Ns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mesn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mesn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maperture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXorZ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Return the classifier\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/helpers/experiment_helpers.py:12\u001B[0m, in \u001B[0;36mcompute_Cs_and_Ns\u001B[0;34m(group, esn, aperture, normalize, XorZ, cache)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_Cs_and_Ns\u001B[39m(group, esn, aperture\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, XorZ\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m---> 12\u001B[0m     Cs \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_Cs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mesn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mesn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maperture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maperture\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mXorZ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- computing negative conceptors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m     Ns \u001B[38;5;241m=\u001B[39m Ns_from_Cs(Cs)\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/helpers/experiment_helpers.py:65\u001B[0m, in \u001B[0;36mcompute_Cs\u001B[0;34m(group, signals, esn, aperture, normalize, XorZ, cache, file_identifier)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, signals \u001B[38;5;129;01min\u001B[39;00m group\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 65\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[43mrun_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mesn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msignals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m aperture \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     67\u001B[0m             Cs\u001B[38;5;241m.\u001B[39mappend(compute_c(X, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/experiments/helpers/experiment_helpers.py:86\u001B[0m, in \u001B[0;36mrun_all\u001B[0;34m(esn, signals, XorZ)\u001B[0m\n\u001B[1;32m     84\u001B[0m X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([])\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m signal \u001B[38;5;129;01min\u001B[39;00m signals:\n\u001B[0;32m---> 86\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mesn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43msignal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXorZ\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mXorZ\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     87\u001B[0m     X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack((X, x)) \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39msize \u001B[38;5;28;01melse\u001B[39;00m x\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "File \u001B[0;32m~/Documents/Work/bsc ai/bt/Bachelor-Thesis/code/lib/esn.py:102\u001B[0m, in \u001B[0;36mESN.run\u001B[0;34m(self, signal, XorZ)\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    101\u001B[0m         p \u001B[38;5;241m=\u001B[39m signal[:, t]\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_dim, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m--> 102\u001B[0m     x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtanh(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_in, p) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb)\n\u001B[1;32m    103\u001B[0m     X[:, t] \u001B[38;5;241m=\u001B[39m x[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Old params:\n",
    "#opt = Classifier(1.5, .2, 1.5, .1) # Z optimal params\n",
    "#opt = Classifier(1.1, .44, 2.57, .1 # X optimal params\n",
    "\n",
    "# Method \"X\"\n",
    "# optx = Classifier(\n",
    "#     0.345252438276947, 0.30700983046650143, 1.6185468676326455, 1\n",
    "# )\n",
    "# Training Accuracy of x : 0.4888995495855654\n",
    "# Test Accuracy of x     : 0.4749240003117936\n",
    "\n",
    "# optx = Classifier(\n",
    "#     1.5, .2, 1.5, .1\n",
    "# )\n",
    "# Training Accuracy of x : 0.5220543162495669\n",
    "# Test Accuracy of x     : 0.5159404474238054\n",
    "\n",
    "\n",
    "# optx = Classifier(\n",
    "#     1.1, .44, 2.57, .1\n",
    "# )\n",
    "#Training Accuracy of x : 0.5168305748780683\n",
    "#Test Accuracy of x     : 0.5273209135552265\n",
    "\n",
    "optx = Classifier(\n",
    "    1.1, .6, 2.57, .1\n",
    ")\n",
    "\n",
    "optx.fit(features_train, labels_train, **{\n",
    "    \"n_mels\":n_mels,\n",
    "    \"XorZ\":'X'\n",
    "})\n",
    "\n",
    "# Training Accuracy of x : 0.5506038076410675\n",
    "# Test Accuracy of x     : 0.5639098916517266\n",
    "\n",
    "# Method \"Z\n",
    "# optz = Classifier(1.5,\n",
    "#     .2,\n",
    "#     1.5,\n",
    "#     .1)\n",
    "#\n",
    "# optz.fit(features_train, labels_train, **{\n",
    "#     \"n_mels\":n_mels,\n",
    "#     \"XorZ\":\"Z\"\n",
    "# })\n",
    "\n",
    "# Scikitlearn\n",
    "\n",
    "\n",
    "#opt = Classifier()\n",
    "#opt = BayesSearchCV(Classifier(), parameters, n_iter=50, cv=3)\n",
    "# opt.fit(features, labels, **{\n",
    "#     \"in_dim\":n_mels,\n",
    "#     \"out_dim\":n_mels\n",
    "# })\n",
    "# print(opt.score(fv, lv))\n",
    "#print(opt.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing\n",
    "### Feature Collection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "\n",
    "features_test, labels_test, _ = dl.collectFeaturesInSegments(\n",
    "    ft='Test',n_mels=n_mels,delta=delta,delta_delta=delta_delta,\n",
    "    long_version=long_version,speakers=[],dr=dr,sentence=[],\n",
    "    subsamples=subsamples,path_option=path_option+\"_test\")\n",
    "\n",
    "_, features_test, labels_test = filter_data(features_test, labels_test, limit=None)\n",
    "\n",
    "print(f'Training Accuracy of x : {optx.score(features_train, labels_train)}')\n",
    "print(f'Test Accuracy of x     : {optx.score(features_test, labels_test)}')\n",
    "\n",
    "# print(f'Training Accuracy of z : {optz.score(features_train, labels_train)}')\n",
    "# print(f'Test Accuracy of z     : {optz.score(features_test, labels_test)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train,\n",
    "                                                    labels_train,\n",
    "                                                    stratify = labels_train,\n",
    "                                                    random_state = 1)\n",
    "\n",
    "# Bayesian Optimization wrapper\n",
    "def objective_function(W_in_scale,\n",
    "                       b_scale,\n",
    "                       spectral_radius,\n",
    "                       weights):\n",
    "\n",
    "    model = Classifier(W_in_scale,\n",
    "                 b_scale,\n",
    "                 spectral_radius,\n",
    "                 weights)\n",
    "    model.fit(X_train, y_train, **const_params)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'W_in_scale': [.01, 2],\n",
    "    'spectral_radius': [0.01, 4],\n",
    "    'b_scale': [0, 2],\n",
    "    'weights': [.01,1]\n",
    "}\n",
    "\n",
    "# Bayesian optimization of the objective function.\n",
    "optimizer = BayesianOptimization(f = objective_function,\n",
    "                                 pbounds = parameters,\n",
    "                                 random_state = 0)\n",
    "optimizer.maximize(init_points = 10, n_iter = 100)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(f\"Best parmaters: {best_params}; f(x) = {optimizer.max['target']}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Progress"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "fig, ax1 = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Scores:\n",
    "ax1.plot(range(1, 1 + len(optimizer.space.target)), optimizer.space.target, color='r', label=\"Accuracy - $f(\\\\rho$, $k_{W^in}$, $k_b$, $r$)\")\n",
    "\n",
    "# Parameters\n",
    "W_in_scale = []\n",
    "b_scale = []\n",
    "spectral_radius = []\n",
    "weights = []\n",
    "\n",
    "for res in optimizer.res:\n",
    "    W_in_scale.append(res[\"params\"][\"W_in_scale\"])\n",
    "    b_scale.append(res[\"params\"][\"b_scale\"])\n",
    "    spectral_radius.append(res[\"params\"][\"spectral_radius\"])\n",
    "    weights.append(res[\"params\"][\"weights\"])\n",
    "\n",
    "if True:\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), W_in_scale, \"--\", label=\"$W^{in}$\")\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), b_scale, \"--\", label=\"$k_b$\")\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), spectral_radius, \"--\", label=\"$r$\")\n",
    "    ax1.plot(range(1, 1 + len(optimizer.space.target)), weights, \"--\", label=\"$\\\\rho$\")\n",
    "\n",
    "ax1.set_xlabel('Iteration', fontsize = 20)\n",
    "ax1.set_ylabel('Accuracy', color=\"r\", fontsize = 20)\n",
    "ax2.set_ylabel('Hyperparameter value', fontsize = 20)\n",
    "\n",
    "ax1.legend(loc=\"upper left\", fontsize = 20)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Displaying Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels_pred = optx.predict(features_test)\n",
    "cm = confusion_matrix(labels_test, labels_pred, labels=phonemes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='',\n",
    "                          cmap=None,\n",
    "                          normalize=True,\n",
    "                          font_size=20):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    from matplotlib import colors\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    norm = colors.LogNorm()\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(cm/np.sum(cm), interpolation='nearest', cmap=cmap, norm=norm)\n",
    "    #plt.imshow(cm/np.max(cm), interpolation='nearest', cmap=cmap, norm=norm)\n",
    "    plt.title(title)\n",
    "    cbar = plt.colorbar(label = \"Number of occurences\")\n",
    "    tick_labs = cbar.ax.get_yticklabels()\n",
    "    cbar.ax.set_yticklabels(tick_labs, fontsize=font_size)\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45, fontsize = font_size)\n",
    "        plt.yticks(tick_marks, target_names, fontsize = font_size)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize = font_size)\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass), fontsize = font_size)\n",
    "    plt.show()\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cm, target_names=phonemes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "mcm = multilabel_confusion_matrix(labels_test, labels_pred, labels = phonemes)\n",
    "mcm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#with open('res.txt','x') as file:\n",
    "#    file.write(opt.score(fv,lv))\n",
    "#    file.write(opt.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
